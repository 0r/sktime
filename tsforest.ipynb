{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Series Random Forest\n",
    "\n",
    "To do:\n",
    "\n",
    "* split code into two files, one for each implementation approach (changing BaseDecisionTree or allowing for pipelines as base_estimators)\n",
    "* clean files (only include objects, methods that had to be changed, inherit the rest)\n",
    "* push to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.tsforest import TSRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sktime.load_data import load_from_web_to_xdataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer(return_X_y=False)\n",
    "\n",
    "y = data.target\n",
    "X = data.data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "# (pd.DataFrame({'feat_importance': clf.feature_importances_}, \n",
    "#               index=data.feature_names)\n",
    "#  .sort_values('feat_importance', ascending=False)\n",
    "#  .head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict_proba(X_test)[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing TimeSeriesRandomForestClassifier\n",
    "generally, requires\n",
    "* to remove input checks, as nested pandas/xpandas do not comply\n",
    "* need to be replaced by new input checks, ideally implemented as part of data container, as input checking is more expensive \n",
    "\n",
    "more specifically, two ways to implement:\n",
    "* change basic DecisionTreeClassifier class to include specific transforms in fit/predict methods\n",
    "* change base_estimator to pipeline with transforms, requires additionally \n",
    "    * to change how parameters are set in construction of individual trees\n",
    "    * add random state attribute to pipeline \n",
    "    * adapt some helper functions for parallel building and accumulating predictions of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1) (50,) (150, 1) (150,)\n"
     ]
    }
   ],
   "source": [
    "cache_path = 'data/'\n",
    "dataset_name = 'GunPoint'\n",
    "\n",
    "X_train, y_train = load_from_web_to_xdataframe(dataset_name, is_train_file=True,\n",
    "                                               cache_path=cache_path) \n",
    "X_test, y_test = load_from_web_to_xdataframe(dataset_name, is_test_file=True,\n",
    "                                             cache_path=cache_path)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_test = pd.Series(y_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features to be calculated for each time-series interval\n",
    "def ts_slope(ts):\n",
    "    \"\"\"\n",
    "    Compute slope of time series using linear regression\n",
    "    \"\"\"\n",
    "    n = ts.shape[0]\n",
    "    if n < 2:\n",
    "        return 0\n",
    "    else:\n",
    "        x = np.arange(n) + 1\n",
    "        y = np.asarray(ts)\n",
    "        beta = ((x*y).mean() - x.mean() * y.mean()) / ((x**2).mean() - (x.mean())**2)\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 9.5 ms, total: 1.18 s\n",
      "Wall time: 1.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.tsforest import TSDecisionTreeClassifier\n",
    "tree = TSDecisionTreeClassifier(criterion='entropy')\n",
    "%time tree.fit(X_train, y_train, check_input=True) \n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.38 s, sys: 11.6 ms, total: 2.39 s\n",
      "Wall time: 2.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TSRandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "             criterion='entropy', max_depth=None, max_features='auto',\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=2, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.tsforest import TSRandomForestClassifier\n",
    "forest = TSRandomForestClassifier(n_estimators=2, criterion='entropy')\n",
    "%time forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.57 s, sys: 23 ms, total: 6.59 s\n",
      "Wall time: 6.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 3.86 ms, total: 2.06 s\n",
      "Wall time: 2.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeSeriesRandomForest(base_estimator=TSPipeline(memory=None,\n",
       "      steps=[('segment', RandomIntervalSegmenter()), ('extract', FeatureExtractor(feature_calculators=[<function mean at 0x1066be1e0>, <function std at 0x1066be268>, <function TimeSeriesRandomForest.__init__.<locals>._ts_slope at 0x106545c80>])), ('clf', DecisionTreeClassifier(class_weight=None, criterion...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))]),\n",
       "            bootstrap=True, class_weight=None, criterion=None,\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=None, min_impurity_split=None,\n",
       "            min_samples_leaf=None, min_samples_split=None,\n",
       "            min_weight_fraction_leaf=None, n_estimators=2, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.tsforest import RandomIntervalSegmenter, FeatureExtractor, TimeSeriesRandomForest\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = TimeSeriesRandomForest(n_estimators=2)\n",
    "\n",
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.77 s, sys: 13.5 ms, total: 5.79 s\n",
      "Wall time: 5.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-series transformer + RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Interval Transformer\n",
    "Split data into random time intervals, series-to-series transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_interval(index):\n",
    "    starts = []\n",
    "    ends = []\n",
    "    m = index.shape[0] # series length\n",
    "    idx = np.arange(1, m + 1)\n",
    "\n",
    "    def random_choice(x, size=None):\n",
    "        return np.random.choice(x, replace=False, size=size)\n",
    "\n",
    "    W = random_choice(idx, size=int(np.sqrt(m)))\n",
    "    for w in W:\n",
    "        size = m - w + 1\n",
    "        start = random_choice(np.arange(1, size+1), size=int(np.sqrt(size))) - 1\n",
    "        starts.extend(start)\n",
    "        for s in start:\n",
    "            end = s + w\n",
    "            ends.append(end)\n",
    "    return starts, ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 100.0\n"
     ]
    }
   ],
   "source": [
    "# test random_interval_sample function\n",
    "n = 10_000\n",
    "mins = np.empty(n)\n",
    "maxs = np.empty(n)\n",
    "index = np.arange(100)\n",
    "for i in range(n):\n",
    "    starts, ends = random_interval(index)\n",
    "    assert all((np.array(e) - np.array(s)) > 0) # only non-empty intervals\n",
    "    assert all([s < e for s, e in zip(starts, ends)])\n",
    "    assert all([e <= index.shape[0] for e in ends]) # within given index\n",
    "    assert all([s >= 0 for s in starts]) # within given index\n",
    "    mins[i] = min(starts)\n",
    "    maxs[i] = max(ends)\n",
    "print(mins.min(), maxs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split series into random intervals\n",
    "df = X_train\n",
    "n_rows, n_cols = df.shape\n",
    "ts_index = df.iloc[0,0].index\n",
    "starts, ends = sample(ts_index)\n",
    "intervals = np.column_stack([starts, ends])\n",
    "n_intervals = intervals.shape[0]\n",
    "\n",
    "interval_data_dict = {}\n",
    "for col in range(n_cols):\n",
    "    col_name = df.columns[col]\n",
    "    for i, (start, end) in enumerate(intervals):\n",
    "        interval_data_list = []\n",
    "        for row in range(n_rows):\n",
    "            interval_data = df.iloc[row, col].iloc[start:end]\n",
    "            interval_data_list.append(interval_data)\n",
    "        interval_data_dict[f'{col_name}_{start}_{end}'] = interval_data_list\n",
    "\n",
    "dft = pd.DataFrame(interval_data_dict)\n",
    "\n",
    "assert dft.shape == (n_rows, n_cols * n_intervals)\n",
    "assert dft.replace([np.inf, -np.inf], np.nan).isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features for each interval\n",
    "Apply feature calculators to each cell, series-to-tabular transformer\n",
    "* For pipelines, when using sklearn classifiers/regressors, check if penultimate estimator is series-to-tabular transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = dft.shape\n",
    "feature_calculators = [np.mean, np.std, ts_slope]\n",
    "n_features = len(feature_calculators)\n",
    "\n",
    "calculated_data_dict = {}\n",
    "for i, calculator in enumerate(feature_calculators):\n",
    "    calculated_data_list = []\n",
    "    for col in range(n_cols):\n",
    "        col_name = f'{dft.columns[col]}_{calculator.__name__}'\n",
    "        calculated_data_dict[col_name] = dft.iloc[:, col].apply(calculator)\n",
    "dfc = pd.DataFrame(calculated_data_dict)\n",
    "assert dfc.shape == (n_rows, n_cols * n_features)\n",
    "assert dfc.replace([np.inf, -np.inf], np.nan).isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using transfomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.ts_forest import RandomIntervalSegmenter, FeatureExtractor\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1) (50,) (150, 1) (150,)\n"
     ]
    }
   ],
   "source": [
    "cache_path = \"C:/temp/sktime_temp_data/\"\n",
    "dataset_name = \"GunPoint\"\n",
    "\n",
    "X_train, y_train = load_from_web_to_xdataframe(dataset_name, \n",
    "                                               is_train_file=True, cache_path=cache_path) \n",
    "X_test, y_test = load_from_web_to_xdataframe(dataset_name,\n",
    "                                             is_test_file=True, cache_path=cache_path)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_test = pd.Series(y_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0     -0.647885\n",
       "1     -0.641992\n",
       "2     -0.63818...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0     -0.644427\n",
       "1     -0.645401\n",
       "2     -0.64705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0     -0.778353\n",
       "1     -0.778279\n",
       "2     -0.77715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0     -0.750060\n",
       "1     -0.748103\n",
       "2     -0.74616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0     -0.599539\n",
       "1     -0.597422\n",
       "2     -0.59926...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dim_0\n",
       "0  0     -0.647885\n",
       "1     -0.641992\n",
       "2     -0.63818...\n",
       "1  0     -0.644427\n",
       "1     -0.645401\n",
       "2     -0.64705...\n",
       "2  0     -0.778353\n",
       "1     -0.778279\n",
       "2     -0.77715...\n",
       "3  0     -0.750060\n",
       "1     -0.748103\n",
       "2     -0.74616...\n",
       "4  0     -0.599539\n",
       "1     -0.597422\n",
       "2     -0.59926..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 273) (150, 273)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_calculators = [np.mean, np.std, ts_slope]\n",
    "\n",
    "# pipeline\n",
    "# set up transformers\n",
    "segmenter = RandomIntervalSegmenter()\n",
    "extractor = FeatureExtractor(feature_calculators=feature_calculators)\n",
    "\n",
    "# fit-transform training data \n",
    "X_train_trans = segmenter.fit_transform(X_train)\n",
    "X_train_trans = extractor.fit_transform(X_train_trans)\n",
    "\n",
    "# transform test data using fitted transformers\n",
    "X_test_trans = segmenter.transform(X_test)\n",
    "X_test_trans = extractor.transform(X_test_trans)\n",
    "print(X_train_trans.shape, X_test_trans.shape)\n",
    "\n",
    "# train and score using random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "clf.fit(X_train_trans, y_train)\n",
    "clf.score(X_test_trans, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [\n",
    "    ('segment', RandomIntervalSegmenter()), \n",
    "    ('extract', FeatureExtractor(feature_calculators=feature_calculators)),\n",
    "    ('classify', RandomForestClassifier(n_estimators=200))\n",
    "]\n",
    "pipe = Pipeline(steps)\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_func():\n",
    "    steps = [\n",
    "    ('segment', RandomIntervalSegmenter()), \n",
    "    ('extract', FeatureExtractor(feature_calculators=feature_calculators)),\n",
    "    ('classify', RandomForestClassifier(n_estimators=200))\n",
    "    ]\n",
    "    pipe = Pipeline(steps)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49333333333333335"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy='prior')\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas indexing does not accept series into single cells\n",
    "\n",
    "* input checking for time-series data more expensive than for tabular data, makes more sense to outsource main checks to dataframe, with check results stored as attributes with can be checked if relevant by methods/estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      "0    3 non-null object\n",
      "1    3 non-null object\n",
      "2    3 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 152.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.zeros((3, 3)), dtype='object')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0,0] = pd.Series(np.random.normal(size=10)) # breaks \n",
    "df[0,0] = pd.Series(np.random.normal(size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
